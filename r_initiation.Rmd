---
title: "Formation R initiation"
output:
  html_document:
    df_print: paged
---


Le menu Session > Set Working Directory permet de sélectionner le répertoire par défaut contenant vos scripts et éventuels fichiers de données.
Vous pouvez également le modifier via une ligne de code :

```{r message=FALSE, warning=FALSE}
setwd('C:/Users/Stephanie/Desktop/R_initiation')
```

Dans Rstudio pour compiler une ligne, vous pouvez placer le curseur dessus et cliquer sur Run, ou bien utiliser le raccourci clavier ctrl+entrée

# Opérations de base

Sous R, les éléments de base sont des objets : vecteurs, matrices, listes, table ...
Ces objets peuvent contenir des éléments de type numérique, booléen (logical : TRUE, FALSE), chaîne de caractère (string), facteur (factor, pour les variables qualitatives prenant un nombre déterminé de modalité). 
La différence entre la table de données (data.frame) et la matrice est tient notamment dans le fait que la première peut contenir des éléments mixtes. 

### Objets et opérations simples

On commence par créer des éléments pour illustrer les opérations de base en R. Le signe `<-` permet d'assigner un contenu à une variable dont on indique le nom à gauche.

```{r message=FALSE, warning=FALSE}
element_a <- 2
element_a
element_b <- 3
element_b
element_c <- element_a/2 + 2*element_b # les opérations -, *, /, sqrt pour racine, ^ pour puissance, log, exp, sont également possibles !
element_c
```

On peut travailler très naturellement sur des vecteurs 

```{r message=FALSE, warning=FALSE}
vecteur_a <- c(2,3,5) 
vecteur_a
```

On peut récupérer un élément d'un vecteur avec l'opérateur `[`

```{r message=FALSE, warning=FALSE}
vecteur_a
vecteur_a[1] #on commence à numéroter à partir de 1 (et non de zéro)
vecteur_a[c(1,3)]
```

Dans le cas où le vecteur correspond à une séquence de nombres, on peut utiliser une syntaxe particulière

```{r message=FALSE, warning=FALSE}
vecteur_a <- c(2,3,4) 
vecteur_b <- 2:4
vecteur_c <- seq(2,4,1) # les arguments de la fonction seq (séquence) correspondent à from, to, by (à partir de 1, jusqu'à 10, avec des écarts de 2)

vecteur_a == vecteur_b # compare les éléments un à un
variable_logique_a <- vecteur_a == vecteur_b
```

Les opérations sur les vecteurs sont très proches des opérations sur les éléments. Une opération entre un vecteur a et un vecteur b revient à réaliser l'opération entre les couples d'éléments issus des deux vecteurs et situés à la même place (il faut que les vecteurs admettent la même taille pour que ça ait un sens)


```{r message=FALSE, warning=FALSE}
vecteur_c <- 2*vecteur_c # on écrase la valeur du vecteur_c
vecteur_c + vecteur_a/2 # exemple d'opération entre deux vecteurs
```

Pour concaténer deux vecteurs, on fera tout simplement 
```{r message=FALSE, warning=FALSE}
vecteur_a
vecteur_b
vecteur_d <- c(vecteur_a,vecteur_b)
vecteur_d
```


Le vecteur est caractérisé notamment par sa taille 

```{r message=FALSE, warning=FALSE}
length(vecteur_a)
```

Il peut-être trié :

```{r message=FALSE, warning=FALSE}
vecteur_d <- c(3,2,1)
order(vecteur_d)
sort(vecteur_d)
```


Remarque, si on ne sait plus la signification des trois arguments de `seq`, on peut aller dans l'aide avec `?seq`

```{r message=FALSE, warning=FALSE}
liste_a <- list(2,3,5)
liste_a
liste_a[[2]]
liste_b <- list(sexe = 2, age = 3, salaire = 5)
liste_b$salaire # si on donne des noms aux éléments de la liste, on peut les récupérer via l'opérateur $
```

Pour concaténer deux listes 

```{r message=FALSE, warning=FALSE}
liste_a
append(liste_a, element_a) # ou liste_b à la place de element_a pour concaténer deux listes
liste_a
```


La fonction `length` convient aussi pour les listes 

```{r message=FALSE, warning=FALSE}
length(liste_a)
```

on peut passer de la liste au vecteur avec la fonction `unlist`

```{r message=FALSE, warning=FALSE}
unlist(liste_a)
```


Pour les matrices : 

```{r message=FALSE, warning=FALSE}
matrice_a <- matrix(1:15,ncol=5) # exemple d'une matrice remplie des chiffres consécutifs de 1 à 15 rangés sur 5 colonnes 
matrice_a
head(matrice_a) # la fonction head permet de visualiser un extrait des données, ici elles sont petites donc c'est la totalité
matrice_a[1,2] # pour récupérer l'élément de la première ligne et de la deuxième colonne 
```

Par défaut, les opérations mathématiques simples se font élément par élément 

```{r message=FALSE, warning=FALSE}
matrice_b <- 2*matrice_a
matrice_a
matrice_b
matrice_b - matrice_a # les opérations se font éléments par élément

t(matrice_b)%*% matrice_a # pour faire des vrais produits matriciels, on utilise l'opérateur %*%, ici t() indique que l'on prend également la transposée
``` 


Pour concaténer deux matrices, on peut soit les mettre côte à côte (`cbind`), soit les empiler (`rbind`). Ces fonctions fonctionnent aussi pour les data.frames.

```{r message=FALSE, warning=FALSE}
matrice_c <- cbind(matrice_a, matrice_b)
matrice_c
dim(matrice_c)
matrice_d <- rbind(matrice_a, matrice_b)
matrice_d
dim(matrice_d)
``` 

Les dimensions de la matrice peuvent être obtenues de la manière suivante :

```{r message=FALSE, warning=FALSE}
nrow(matrice_a)
ncol(matrice_a)
dim(matrice_a)
```

Les tables de données ou data.frame est sans doute le format qu'on utilisera le plus dans la suite. 

```{r message=FALSE, warning=FALSE}
df_a <- as.data.frame(matrice_a) # on commence par transformer la matrice en data.frame, l'opération symétrique as.matrix() est possible
head(df_a) 
names(df_a) # ici le data.frame provient de la conversion d'une matrice, il n'y a donc pas de noms de colonnes à part ceux qui sont donnés par défaut V1, V2...
names(df_a) <- c('a','b','c','d','e') # on peut changer le nom des colonnes simplement
```

Pour récupérer de l'information dans la table de données, on peut procéder de différentes manières 

```{r message=FALSE, warning=FALSE}
df_a$b # avec l'opérateur $, on peut récupérer directement la colonne b
df_a[['b']] # revient au même
df_a[[2]] # correspond également car il s'agit de la 2e colonne
df_a$e <- 1 # permet de construire une nouvelle colonne e remplie de 1 
head(df_a)
df_a$f <- df_a$a + df_a$b # permet de construire une nouvelle colonne qui serait la somme des deux premières, les opération -, *, /, sqrt pour racine carrée, log, exp, ^, sont également possibles ! 
head(df_a)
df_a$f <- sqrt(df_a$a) + df_a$b^2 # permet de construire une nouvelle colonne qui serait la somme des deux premières, les opération -, *, /, sqrt pour racine 
```

Vérifions le type de ces objets avec la fonction `class`

```{r message=FALSE, warning=FALSE}
class(element_a)
class(vecteur_a)
class(variable_logique_a)
class(liste_a)
class(matrice_a)
class(df_a)
```

Nous avons créé un certain nombre de variables qui sont disponibles dans votre environnement (généralement en haut à droite par défaut)
On peut aussi utiliser la fonction `ls` pour voir la liste des objets dont on dispose, et `rm` pour en supprimer.

```{r message=FALSE, warning=FALSE}
ls()
rm(element_a)
ls()
```


### Boucle, condition
 
Reprenons le cas où on a un data.frame simple. On veut calculer la moyenne, la somme, le maximum et le minimum de chaque colonne.  
Une manière de le faire serait de faire une boucle sur le nombre de colonnes et d'appliquer la fonction `mean`, `sum`, `max`, `min`, à chaque colonne tour à tour.


```{r message=FALSE, warning=FALSE}
nb_col <- ncol(df_a) 
mean_col <- NULL # on commence par créer une variable vide, dans laquelle on va ajouter itérativement les moyenne de chaque colonne

for (i in 1:nb_col){
  print(i)
  mean_temp <- mean(df_a[[i]])
  print(mean_temp)
  mean_col <- c(mean_col, mean_temp)
  print(mean_col)
  print('---------')
}
``` 

En réalité, les boucles sont à éviter en R, elles ne sont pas efficaces, on leur préférera la fonction `lapply` qui distribue la fonction souhaitée sur chaque élément d'une liste. Un data.frame peut-être vu comme une liste de vecteurs. 

```{r message=FALSE, warning=FALSE}
mean_col <- lapply(df_a, mean) # ici la fonction est particulièrement simple car mean est déjà une fonction R
mean_col <- sapply(df_a, mean) # sapply procède de même mais renvoie un vecteur
mean_col
```

Admettons qu'on cherche à appliquer une fonction personnalisée 

```{r message=FALSE, warning=FALSE}
mean_personnalisee <- function(vect){
  return(sum(vect)/length(vect))
}
```


```{r message=FALSE, warning=FALSE}
mean_col <- sapply(df_a, function(vect) mean_personnalisee(vect))
mean_col
```

Appliquée sur un vecteur, `lapply` le convertit en liste, on peut repasser à un format vecteur avec la fonction `unlist`

```{r message=FALSE, warning=FALSE}
fonction_personnalisee <- function(x){
  return(x*log(x))
}
```

```{r message=FALSE, warning=FALSE}
vecteur_a_transforme <- lapply(vecteur_a, function(x) fonction_personnalisee(x))
class(vecteur_a_transforme)
vecteur_a_transforme
unlist(vecteur_a_transforme)
vecteur_a*log(vecteur_a) # aurait marché aussi !
```

`apply` s'applique aussi à des matrices, on indique alors si la fonction à distribuer doit être distribuée en ligne ou en colonne 

```{r message=FALSE, warning=FALSE}
matrice_a
apply(matrice_a,1,sum) # ici on applique la fonction somme, autrement dit on somme les éléments par ligne
apply(matrice_a,2,sum) # par colonne
```

La syntaxe de la condition est très proche de celle de la boucle, sauf que l'on remplace `for` par `if`

```{r message=FALSE, warning=FALSE}
fonction_personnalisee <- function(x){
  if (x>0){res <- x*log(x)}
  else {res <- 0}
  return(res)
}
```

```{r message=FALSE, warning=FALSE}
vecteur_d <- c(0,-1,2)
sapply(vecteur_d, function(x) fonction_personnalisee(x))
abs(vecteur_d) # rmq : abs permet de passer un élément en valeur absolue (s'applique également aux vecteurs sans recours à lapply)
```

Ici on a inclus la condition dans une fonction, mais ce n'est pas indispensable ! On peut vouloir aussi tester la différence `!=` plutôt que l'égalité, '<' ou '>', et si on a plusieurs conditions, on mettra chacune entre parenthèse et on utilisera `|` pour dire "ou" et `&` pour dire "et" (par exemple `(b-3==a) & (b>=a)`).

Parfois, on n'a pas besoin de passer par `if` pour appliquer une condition, par exemple si on veut récupérer seulement les éléments de vecteur_d supérieurs ou égaux à 0. Cela revient à dire qu'on teste la condition sur chaque élément et qu'on conserve vecteur_d[i] pour i tel que vecteur_d[i]>=0
 
```{r message=FALSE, warning=FALSE}
vecteur_d
vecteur_d[vecteur_d>=0]
```

Et ça fonctionne aussi avec les data.frames

```{r message=FALSE, warning=FALSE}
df_a[df_a$a>2] # on ne garde que les colonnes qui vérifient cette condition
```

### Le type chaîne de caractère 

Il arrive que les objets que l'on manipule ne soit pas numériques, on parle alors de `character` ou de `factor`. C'est le cas par exemple des noms de colonnes de `df_a`

```{r message=FALSE, warning=FALSE}
class(names(df_a))
```

On peut aussi réaliser des opérations, par exemple de concaténation. Imaginons que l'on souhaite préciser les noms de colonnes en indiquant qu'il s'agit de département.  

```{r message=FALSE, warning=FALSE}
paste('departement','test',sep='_')
paste(rep('departement',5), names(df_a),sep='_') 
names(df_a) <- paste(rep('departement',5), names(df_a),sep='_') # revient à faire apply de paste sur tous les éléments du vecteur names(df_a)
rep('departement',5) # rep est la fonction qui permet de créer des vecteurs d'une taille donnée contenant toujours le même élément qui pourrait être numérique
```

On peut récupérer une partie d'une chaine de caractère simplement 

```{r message=FALSE, warning=FALSE}
character_a <- 'departement_a' 
class(character_a)
substr(character_a,1,10)
strsplit(character_a,'_')
strsplit(character_a,'_')[[1]][[2]]
```

La taille d'une chaine de caractères correspond au nombre de caractères 

```{r message=FALSE, warning=FALSE}
nchar(character_a)
```

Les facteurs correspondent aux modalités d'une variable qualitative. 

```{r message=FALSE, warning=FALSE}
col_df_a <- names(df_a)
col_df_a_fact <- as.factor(col_df_a)
is.character(col_df_a_fact)
class(col_df_a)
class(col_df_a_fact)
```

On ne peut pas rajouter un élément qui n'est pas dans la liste des facteurs naïvement 

```{r message=FALSE, warning=FALSE}
levels(col_df_a_fact)
col_df_a_fact <- c(col_df_a_fact, 'departement_z')
class(col_df_a_fact) # attention cette opération a converti col_df_a_fact en character
col_df_a_fact 
levels(col_df_a_fact) 
col_df_a_fact <- as.factor(col_df_a)
as.character(col_df_a_fact) # parfois on préfère revenir aux chaines de caractères pour éviter ce type de problèmes 
```

Lorsque l'on charge des tables de données, il est possible que R ne reconnaisse pas une variable numérique et qu'elle soit codée en facteurs. Dans ce cas, il faut la convertir en chaines de caractères avant de la convertir en nombre, car les facteurs sont associés à des numéros qui correspondent aux modalités. 


```{r message=FALSE, warning=FALSE}
nombres <- c(4,2,3)
facteurs <- as.factor(nombres)
facteurs
as.numeric(facteurs)
as.numeric(as.character(facteurs))
```


# Générer des variables aléatoires 

Il est parfois intéressant de simuler des données. Générons 50 observations tirées d'une variable suivant une loi normale de moyenne 20 et d'écart-type 10.
 
```{r message=FALSE, warning=FALSE}
set.seed(123) # permet de reproduire les mêmes résultats d'une fois sur l'autre en dépit de l'aléa présent
n <- 50
Y <- rnorm(n,20,5)

mean(Y) # moyenne
sd(Y) # écart-type
sd(Y)/sqrt(length(Y)) # écart-type de la moyenne

summary(Y) # quartiles et moyenne
```

On peut représenter graphiquement cette variable 
 
```{r message=FALSE, warning=FALSE}
boxplot(Y) # diagramme boîte

hist(Y, probability=T, col="blue") # histogramme de la densité

lines(density(Y), col="red", lwd=2) # estimation par la méthode du noyau
# tracer la loi théorique
x <- 1:100
curve(dnorm(x,mean=20,sd=5),add=TRUE,col="green",lwd=2) # l'argument add permet de rajouter ce contour sur le graphique
```

On peut générer des observations tirées dans une loi uniforme sur [a,b]
 
```{r message=FALSE, warning=FALSE}
X <- runif(n,50,100)
hist(X)
```

Vous pouvez augmenter la valeur de `n` pour voir ce que ça donne 



# Lecture et exploration de données 

Pour cette entrée en matière de l'exploration d'un vrai fichier de donnée, nous nous sommes fortement inspirés de l'exercice suivant https://www.math.univ-toulouse.fr/~besse/Wikistat/pdf/st-scenar-statlab.pdf

Une  étude réalisée  entre  1961  et  1973  dans  la  maternité  d'un  hôpital d'Oakland  (Californie)  avait  pour  but  de  rechercher  si  certaines  caractéristiques  des  parents  avaient  une  influence  sur  le  développement  de  l'enfant. Parmi les variables collectées, 19 variables décrites dans le tableau ci-dessous ont  été  observées  sur  115  familles  ou  unités  statistiques.  Ces  variables  décrivent des informations médicales et socio-économiques concernant le bébé et ses parents au moment de la naissance puis dix ans plus tard, permettant ainsi de se poser différentes questions de nature plutôt épidémiologique :
-  Influence ou non de la consommation de cigarettes sur le sexe de l'enfant, sur son poids, sur sa taille,
-  sur l'évolution du poids de la mère en 10 ans,
-  sur les liaisons entre les caractéristiques des parents (poids, taille, rhésus) et celles de leur enfant

![](C:/Users/Stephanie/Desktop/R_initiation/list_var.png)

### Chargement et exploration sommaire

```{r message=FALSE, warning=FALSE}
famil=read.csv2("statlab.csv") # lecture du fichier csv
head(famil) # aperçu du haut des données
dim(famil) # combien de colonnes et de ligne 
summary(famil) # quelques statistiques classiques
```

La fonction `summary` fournit déjà beaucoup d'information sur chaque variable. Mais on pourrait réappliquer les fonctions vues précedemment pour calculer ces indicateurs et/ou les représenter graphiquement (moyenne, écart-type, quantiles, diagramme boîte, histogramme). Cela permet notamment de repérer les valeurs atypiques, l'hétérogénéité des variances, les distributions dissymétriques... 


```{r message=FALSE, warning=FALSE}
sapply(famil, mean) # les moyennes de chaque variable 
sapply(famil, sd) # les écarts type
boxplot(famil$ET0) # taille de l'enfant
boxplot(famil$EP0) # poids de l'enfant
hist(famil$ET0)
hist(famil$EP0)
```

Pour les variables qualitatives, on aura plutôt tendance à considérer les fréquences des modalités.

```{r message=FALSE, warning=FALSE}
table(famil$ESx)
barplot(table(famil$ESx)) # sexe de l'enfant
barplot(table(famil$MCig0)) # consommation de cigarettes
pie(table(famil$MCig10)) # consommation de cigarettes dix ans après 
```

Pour analyser grossièrement les liaisons, on peut regarder un nuage de points 

```{r message=FALSE, warning=FALSE}
pairs(famil[,c(3:6,8,9,11,12,14,16:19)])
plot(EP10~PP10,data=famil) # poids de l'enfant à 10 ans, poids du père
plot(EP10~ET10,data=famil) # poids de l'enfant à 10 ans, taille à 10 ans
```

Pour analyser grossièrement les liaisons entre variables qualitatives, on aura recours aux tables de contingence 

```{r message=FALSE, warning=FALSE}
table(famil$ESx,famil$ERh) # sexe et rhésus

addmargins(table(famil$ESx,famil$ERh)) # avec les marges

prop.table(table(famil$ESx,famil$ERh)) # fréquences relatives
```

Une manière de représenter graphiquement ces tables est d'utiliser une moisaique

```{r message=FALSE, warning=FALSE}
mosaicplot(table(famil$ESx,famil$ERh))
addmargins(table(famil$MCig0,famil$ESx)) # consommation de cigarette et sexe de l'enfant
mosaicplot(table(famil$MCig0,famil$ESx))
```

Si l'on veut croiser variables qualitatives et quantitatives, on peut utiliser les boites 

```{r message=FALSE, warning=FALSE}
boxplot(EP0~ESx,data=famil) # poids de l'enfant vs sexe
boxplot(EP0~MCig0,data=famil) # poids de l'enfant vs consommation de cigarettes
```

### Tests de liaison

Quelques tests, imaginons qu'on veuille tester l'indépendance de deux variables qualitatives. Le test du $\Khi^2$ sera adapté à ce problème (dans le cas 
où les effectifs d'une modalité sont trop faibles, il faut regrouper les modalités). 

```{r message=FALSE, warning=FALSE}
chisq.test(table(famil$ESx,famil$ERh)) # Sexe de l'enfant vs Rhésus
chisq.test(table(famil$ESx,famil$MCig0)) # Sexe de l'enfant vs consommation de cigarettes
```

On s'intéresse à l'influence du sexe sur la taille à la naissance. Tester l'égalité des deux moyennes nécessite de vérifier préalablement plusieurs points : la normalité des distributions dans chaque classe à moins que l'échantillon soit considéré de taille suffisamment grande, le caractère indépendant ou appariés des échantillons, l'égalité ou non des variances à l'intérieur de chaque groupe. On dispose de deux échantillons indépendants : les garçons et les filles. Testons les autres hypothèses.


```{r message=FALSE, warning=FALSE}
# Normalité des distributions (facultatif car n grand ici)
shapiro.test(famil[famil$ESx=="M","ET0"]) 
shapiro.test(famil[famil$ESx=="F","ET0"])
# égalité des variances (test de Fisher)
var.test(ET0~ESx,data=famil)
```

Le test de comparaison des moyennes à utiliser (Student vs. Welsh) dépend du résultat précédent concernant l'égalité des variances.

```{r message=FALSE, warning=FALSE}
t.test(ET0~ESx,var.equal=F, data=famil) # si les variances sont différentes c'est un test de Welsh

t.test(ET0~ESx,var.equal=T, data=famil) # Dans le cas où elles sont considérées égales, c'est un test de Student.
```

Dans le cas d'échantillons appariés, par exemple si on se propose d'étudier l'évolution du poids de la mère au moment de la naissance et dix ans après, on utilise l'option `paired=TRUE`

```{r message=FALSE, warning=FALSE}
t.test(famil$MP0, famil$MP10,paired=TRUE)
```

Remarques : 
- si l'hypothèse de normalité des distributions n'est pas vérifiée et si l'échantillon est trop réduit, c'est un test non-paramétrique qu'il faut mettre en ouvre. Les tests non-paramétriques sont basés sur les rangs des observations et donc sur les comparaisons des médianes des échantillons (wilcoxson). 

- Si l'on veut tester l'indépendance entre une variable qualitative et quantitative, l'ANOVA associée à un test de Fisher est sans doute le test le plus utilisé ; il revient au test de Student lorsque la variable qualitative n'a que deux modalités.


### Régression simple et multiple

La régression simple permet de tester l'influence éventuelle d'une variable sur une autre et plus précisément, dans le cas de cet exemple, d'expliquer la taille  de  l'enfant  à  10  ans. On estime le modèle avec la fonction `lm`  


```{r message=FALSE, warning=FALSE}
res1.reg=lm(ET10 ~ PT, data = famil)
names(res1.reg) # liste des résultats
```

Les graphiques suivants permettent de s'assurer de la validité du modèle, et notamment de statuer sur l'homoscédasticité des résidus, leur normalité, la bonne linéarité du modèle.

```{r message=FALSE, warning=FALSE}
qqnorm(res1.reg$residuals) # normalité des résidus
qqline(res1.reg$residuals)
shapiro.test(res1.reg$residuals) 
```


Les résidus sont "grands" si, une fois normalisés ou plutôt "studentisés", ils sont de valeur absolue plus grande que 2. 

```{r message=FALSE, warning=FALSE}
res.student=rstudent(res1.reg)
ychap=res1.reg$fitted.values
plot(res.student~ychap,ylab="Résidus") 
abline(h=c(-2,0,2),lty=c(2,1,2)) # rajoute une ligne horizontale
```

Une observation est influente si elle a un grand résidu est est associée à une grande valeur sur la diagonale de la hat matrix. Cela correspond à une valeur élevée (plus grande que 1) de la distance de Cook.

```{r message=FALSE, warning=FALSE}
cook=cooks.distance(res1.reg) # repérage de points influents
plot(cook~ychap,ylab="Distance de Cook")
abline(h=c(0,1),lty=c(1,2))
```

La significativité du modèle peut être analysée via la fonction `summary` : 

```{r message=FALSE, warning=FALSE}
summary(res1.reg)
```

La régression linéaire simple conduit à un modèle très mal ajusté. Le modèle linéaire multiple ci-dessous, plus complexe, recherche un meilleur ajustement des données.

```{r message=FALSE, warning=FALSE}
res2.reg=lm(ET10~ET0+EP0+MA0+MP0+MT+MP10+PA0+PT+PP10+RF0+RF10, data = famil)
plot(res2.reg) # diagnostics des résidus
summary(res2.reg) # résultats 
```


### ACP

On peut aller plus loin dans l'exploration sur les données sans fixer une variable cible, en réalisant une analyse en composantes principales. On ne garde que les variables quantitatives.  

Pour cela, on va faire appel à la librairie `prcomp`, ce n'est pas la seule qui permet de faire une ACP. Assez régulièrement sous R, on va avoir besoin de mobiliser des packages ou librairies. La  liste  complète  des packages disponibles gratuitement est consultable sur le site du CRAN. L'installation d'un package supplémentaire peut se faire via le menu Packages>Installer le(s) package(s) et en choisissant un site miroir du CRAN. On peut également télécharger l'archive .zip correspondant au package et utiliser ensuite Packages/Installer depuis des fichiers zip

On peut sinon taper la commande :

```{r message=FALSE, warning=FALSE}
#install.packages('prcomp') # décommenter pour installer
```


```{r message=FALSE, warning=FALSE}
data=famil[,c(3:6,8,9,11,12,14,16:19)] # liste des varaibles quantitatives

noms=dimnames(data)[[2]];noms
names(data)

res.pca=prcomp(data,scale=T)
plot(res.pca) # décroissance des valeurs propres

summary(res.pca) # parts de variance expliquée

biplot(res.pca) # biplot du premier plan principal
plot(res.pca$x,col=as.integer(famil$MCig0))
text(10*res.pca$rotation,noms,col="blue")
abline(h=0,v=0,lty=2)
```


# Exploration avancée (dplyr + ggplot2) sur données des urgences 

!!!!!!! a faire !!!!!!!
- lecture ecriture fichier sas et xls
- dplyr et ggplot2 (croiser délai d'attente et personnel)
- gestion des valeurs manquantes 
- leaflet sur la loc des urgences

http://www.data.drees.sante.gouv.fr/ReportFolders/reportFolders.aspx?IF_ActivePath=P,432,507
les noms des tableaux donne les exemples de stat à faire 

Cet exercice mobilise l'enquête nationale sur les structures des urgences hospitalières 2013. Un jour donné, le 11 juin 2013 de 8h à 8h le 
lendemain, un questionnaire papié renseigné en temps réel en parallèle de la prise en charge par tous les points d'accueils (736) des établissements de santé autorisés pour l'activité d'accueil et de traitement des urgences (634) et pour tous les patients (52018). 

de 87 à 90 le nombre de patient présent en 4 postes * 5 tranches horaires dejà avec ggplot2 (aggregate pour prendre le nombre moyen)
pareil la distribution des professionnels * 5 tranches 
A 103 c'est le nombre de passage sur les 24h, ne rentre pas dans les variables de la tranche A attention, permet de faire des groupes de structures comme dans l ER



```{r message=FALSE, warning=FALSE}
urgences <- read.csv2("enq_urgences_structure.csv", sep=',') # lecture du fichier csv
head(urgences) # aperçu du haut des données
dim(urgences) # combien de colonnes et de ligne 
#???names(urgences)
dim(urgences)
```

Pour chaque heure de pointage (8h, 12h, 18h, 22h, 8h) indiquée par les lettres A, B, C, D, E, on retient pour l'exercice les variables suivantes (cf questionnaire dans le dossier) :

Les variables de présence de patients aux urgences :

- 87 : Nombre de patients en cours d'évaluation, non admis (nombre de patients présents hors lit i.e. box, salle d'attente) pour lesquels une décision d'hospitalisation n'a pas été prise
- 88 : Nombre de patients admis et en attente d'hospitalisation sur un brancard ou un fauteuil roulant (« boarding »)
- 89 : Nombre de patients présents en lit (UHCD) qui ne sont pas en attente d'hospitalisation
- 90 : Nombre de patients présents en lit (UHCD) en attente d'hospitalisation

Les variables d'organisation du travail : 

- 92 : Nombre de médecins urgentistes
- 93 : Nombre de médecins non urgentistes
- 94 : Nombre d'interne
- 95 : Nombre de médecins intérimaires et extérieurs
- 96 : Nombre de cadres de santé
- 97 : Nombre d'infirmiers diplômés d'État (IDE)
- 98 : Nombre d'aide soignants(AS)
- 99 : Nombre d'agents de service hospitalier (ASH)
- 100 : Nombre de secrétaires 
- 101 : Nombre de brancardiers

Les variables liées à l'établissement :

A103 : Nombre de passages sur les 24 heures
A4 : type d'accueil
A2 : numéro finess de l'établissement

```{r message=FALSE, warning=FALSE}
col_a_garder <- c(87:90,92:101)
nbcol <- length(col_a_garder)
col_a_garder <- unlist(lapply(c('A','B','C','D','E'), function(lettre) paste(rep('ID_',nbcol),rep(lettre,nbcol),col_a_garder,sep=''))) 
col_a_garder
col_a_garder <- c(col_a_garder, "ID_A103","ID_A4","ID_A2")
urgences <- urgences[,col_a_garder]
dim(urgences)
```

Regardons d'abord la répartition des types d'établissement

```{r message=FALSE, warning=FALSE}
table(urgences$ID_A4) # répartition des structures
# ça ne somme pas du tout à 
```


On va regarder la distribution du nombre de passages sur les 24 heures dans l'établissement, c'est un proxy de la taille de ce dernier. On va créer des modalités pour comparer des services d'urgences comparables. Pour les graphiques, on va désormais utiliser la librairie `ggplot2`, installez-là si elle n'est pas installée.

```{r message=FALSE, warning=FALSE}
library(ggplot2)
ggplot(urgences, aes(x=ID_A103)) + geom_histogram(fill="blue", alpha=0.4) # alpha gère la transparence 
```

Comparons cette distribution par type de structure :


```{r message=FALSE, warning=FALSE}
p <- ggplot(urgences, aes(x=ID_A103, fill = ID_A4)) + geom_histogram(alpha=0.4) + theme(legend.position="top") # en précisant la couleur par un nom de variables, on demande le tracé d'un histogramme pour chaque modalité 
p
```

Avec la fonction `ggplotly` de `plotly` on peut rendre le graphique interactif.

```{r message=FALSE, warning=FALSE}
library(plotly)
ggplotly(p)
```

On va désormais transformer cette variable en variable qualitative pour rassembler les établissements par proxy de taille 

```{r message=FALSE, warning=FALSE}
valeurs_manquantes <- is.na(urgences$ID_A103) # on regarde si la variable admet des valeurs manquantes, 
head(valeurs_manquantes)
(TRUE %in% valeurs_manquantes) # c'est le cas 
sum(valeurs_manquantes) # nb de valeurs manquantes
dim(urgences)
urgences <- na.omit(urgences) # si on veut retirer toutes les lignes avec au moins une valeur manquante (pas toujours souhaitable)
dim(urgences)

# on crée une nouvelle colonne
urgences$nb_passages <- cut(urgences$ID_A103, breaks = c(0,40,80,max(urgences$ID_A103, na.rm=T))) # max, comme la plupart des fonctions renverra une erreur si appliqué sur un vecteur contenant des NA, on les enlève pour le calcul avec l'option na.rm 
table(urgences$nb_passages)
```


On voudrait maintenant regarder le nombre de patients ou les effectifs par tranche horaire, on voit bien qu'il sera plus facile d'avoir une variable tranche horaire. Il suffit de récupérer les colonnes correspondant à chaque horaire, de les renommer, puis de les empiler en créant une colonne horaire 

```{r message=FALSE, warning=FALSE}
horaire_8 <- urgences[,c(paste('ID_','A',c(87:90,92:101), sep =''),'ID_A103','ID_A4','nb_passages','ID_A2')]
horaire_12 <- urgences[,c(paste('ID_','B',c(87:90,92:101), sep =''),'ID_A103','ID_A4','nb_passages','ID_A2')]
horaire_18 <- urgences[,c(paste('ID_','C',c(87:90,92:101), sep =''),'ID_A103','ID_A4','nb_passages','ID_A2')]
horaire_22 <- urgences[,c(paste('ID_','D',c(87:90,92:101), sep =''),'ID_A103','ID_A4','nb_passages','ID_A2')]
horaire_8_ <- urgences[,c(paste('ID_','E',c(87:90,92:101), sep =''),'ID_A103','ID_A4','nb_passages','ID_A2')]
head(horaire_8)

#on rajoute une colonne d'heure
horaire_8$heure <- '8h'
horaire_12$heure <- '12h'
horaire_18$heure <- '18h'
horaire_22$heure <- '22h'
horaire_8_$heure <- '8h'

#pour pouvoir empiler les 5 tables il faut qu'elles aient les mêmes noms de colonnes 
names(horaire_8) <- c(paste('ID_',c(87:90,92:101), sep =''),'ID_A103','ID_A4','nb_passages','ID_A2','heure')
names(horaire_12) <- c(paste('ID_',c(87:90,92:101), sep =''),'ID_A103','ID_A4','nb_passages','ID_A2','heure')
names(horaire_18) <- c(paste('ID_',c(87:90,92:101), sep =''),'ID_A103','ID_A4','nb_passages','ID_A2','heure')
names(horaire_22) <- c(paste('ID_',c(87:90,92:101), sep =''),'ID_A103','ID_A4','nb_passages','ID_A2','heure')
names(horaire_8_) <- c(paste('ID_',c(87:90,92:101), sep =''),'ID_A103','ID_A4','nb_passages','ID_A2','heure')

urgences2 <- rbind(horaire_8, horaire_12, horaire_18, horaire_22, horaire_8_)
dim(urgences)
dim(urgences2)
head(urgences2)
```

On peut regarder le nombre de médecin urgentiste `ID_92` en fonction de la tranche horaire et de la taille de la structure avec un graphique à boites.


```{r message=FALSE, warning=FALSE}
sapply(urgences2, class) #attention certaines variables numériques ne sont pas considérées comme telles !
urgences2[,1:15] <- lapply(urgences2[,1:15],function(v) as.numeric(as.character(v)))

p<-ggplot(data = urgences2, aes(x=heure, y=ID_92, color=nb_passages)) + geom_boxplot()
p
```




Si on veut plutôt regarder l'évolution du nombre moyen dans le cours de la journée, il va falloir d'abord calculer cette moyenne par groupe. Pour cela on va faire appel au package `dplyr`, vous devez l'installer si ce n'est pas déjà fait.

```{r message=FALSE, warning=FALSE}
library(dplyr)
XXX geombar
ggplot(data = urgences2, aes(x=heure, y=ID_92, group = nb_passages, color = nb_passages)) + geom_line() + geom_point()
```

Maintenant on va regarder l'évolution de la distribution des effectifs de personnels et de patients dans le temps. Pour présenter les différents graphiques côte à côte, on va utiliser l'option `facet` de `ggplot2` mais avant cela, il faut retravailler encore sur la forme des données.

XXXX melt + ggplot2 personnels (refaite la meme chose pour les patients)

Enfin, nous allons représenter la densité du nombre de patients au cours de la journée sur une carte. Pour cela, on va lire une table SAS et la fusionner avec notre table puis avoir recours au package XX.  



ggplot(mtcars, aes(x=wt, y=mpg)) +
  geom_point(size=2, shape=23)
  
  http://www.sthda.com/french/wiki/ggplot2-graphique-lineaire-guide-de-demarrage-rapide-logiciel-r-et-visualisation-de-donnees
http://www.sthda.com/french/wiki/logiciel-r



melt
facet distrib type de patient par h et type de medecin
ce que ggplot fait tout seul et dplyr

sas
merge 
leaflet

unique ?
dedup ?
proc sas 
Rq lecture d'une table excel aussi ?

```{r message=FALSE, warning=FALSE}
urgences=read.csv2("enq_urgences_structure.csv", sep=',') # lecture du fichier csv
head(urgences) # aperçu du haut des données
dim(urgences) # combien de colonnes et de ligne 
names(urgences)
dim(urgences)
```


Hist tranche d'age
tranche d'age par heure d'enregistrement
tranche d'age par delai par heure d'enregistrement

48711 questionnaires ont été renseignés (93,6% de taux de réponse)
.
Après ponctuelles mises en cohérence, 2% de défaut 
des informations temporelles
.
Age <16 ans 28%, >=75 ans 12%
.
CHU 20%, CH 61%, PSPH 6%, OQN 13%
.
Passages avec
-
Imagerie conventionnelle 39%, écho, TDM, IRM 12%
-
Biologie 35%, avis spécialisé 20%, actes de soins 41%
-
Minuit
-
8h 9%, SAUV 5%, Hospitalisation 20%


ggplot2
ggplotly
dplyr
lecture sas
merge 
leaflet

lire l'excel

# Complément SAS -> R 

